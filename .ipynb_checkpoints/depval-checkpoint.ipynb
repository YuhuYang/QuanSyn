{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "###indicators form dependency grammar and valency grammar,such as dependency distance, dependency direction, \n",
    "###probabilistic valency pattern, valency and so on.###\n",
    "from conllu import parse_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdd(data, deprel=None, upos=None, depdirection=None):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Dependency Distance (MDD) for a conllu format data.\n",
    "\n",
    "    This function computes the average distance between words and their syntactic\n",
    "    heads based on optional filters such as dependency relation (deprel),\n",
    "    Universal POS (upos), and dependency direction (depdirection).\n",
    "\n",
    "    Args:\n",
    "        data (conllu): A list of sentences, each represented as a list of word dictionaries.\n",
    "                     Each word dictionary should contain 'id', 'head', 'deprel', and 'upos' keys.\n",
    "        deprel (str, optional): The dependency relation to consider. If None, all relations are considered.\n",
    "        upos (str, optional): The Universal POS tag to consider. If None, all tags are considered.\n",
    "        depdirection (str, optional): The desired dependency direction: 'head_initial' or 'head_final'.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated Mean Dependency Distance (MDD).\n",
    "\n",
    "    Example:\n",
    "        data = [\n",
    "            [{'id': 1, 'head': 2, 'deprel': 'nsubj', 'upos': 'NOUN'}, {'id': 2, 'head': 0, 'deprel': 'root', 'upos': 'VERB'}],\n",
    "            [{'id': 1, 'head': 3, 'deprel': 'nsubj', 'upos': 'NOUN'}, {'id': 2, 'head': 3, 'deprel': 'aux', 'upos': 'AUX'},\n",
    "             {'id': 3, 'head': 0, 'deprel': 'root', 'upos': 'VERB'}]\n",
    "        ]\n",
    "        mdd = get_mdd(data, deprel='nsubj', depdirection='head_initial')\n",
    "        print(f\"Mean Dependency Distance: {mdd}\")\n",
    "\n",
    "    Note:\n",
    "        - The function assumes that the input data follows the specified format.\n",
    "        - The 'id' key in each word dictionary represents the word's index in the sentence.\n",
    "        - The 'head' key represents the index of the head word to which the current word is dependent.\n",
    "        - The 'deprel' key represents the dependency relation between the current word and its head.\n",
    "        - The 'upos' key represents the Universal POS tag of the current word.\n",
    "        - If no suitable dependencies are found, the function returns 0.0.\n",
    "    \"\"\"\n",
    "    word_dd = []  \n",
    "    for sentence in parse_incr(data):    \n",
    "        for word in sentence:\n",
    "            if deprel is not None and word['deprel'] == deprel:\n",
    "                dd = abs(word['head'] - word['id'])\n",
    "                word_dd.append(dd)\n",
    "            elif upos is not None and sentence[word['head'] - 1]['upos'] == upos and word['head'] != 0:\n",
    "                dd = abs(word['head'] - word['id'])\n",
    "            elif depdirection == 'head_final' and word['deprel'] not in ['root','punct'] and word['head'] > word['id']:\n",
    "                dd = abs(word['head'] - word['id'])\n",
    "                word_dd.append(dd)\n",
    "            elif depdirection == 'head_initial' and word['deprel'] not in ['root','punct'] and word['head'] < word['id']:\n",
    "                dd = abs(word['head'] - word['id'])\n",
    "                word_dd.append(dd)\n",
    "            elif deprel is None and upos is None and word['deprel'] not in ['root','punct']:\n",
    "                dd = abs(word['head'] - word['id'])\n",
    "                word_dd.append(dd)\n",
    "    mdd = sum(word_dd) / len(word_dd)\n",
    "    return mdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdd(data, deprel=None):\n",
    "    \"\"\"\n",
    "    Calculate the Proportion of Dependency Directions (PDD) for a conllu format data.\n",
    "\n",
    "    This function computes the proportion of head-initial and head-final dependencies\n",
    "    based on the provided dependency relation (deprel) within the input data.\n",
    "\n",
    "    Args:\n",
    "        data (conllu): A list of sentences, each represented as a list of word dictionaries.\n",
    "                     Each word dictionary should contain 'id', 'head', and 'deprel' keys.\n",
    "        deprel (str, optional): The dependency relation to consider. If None, all relations are considered.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two values:\n",
    "               - proportion_head_initial (float): The proportion of head-initial dependencies.\n",
    "               - proportion_head_final (float): The proportion of head-final dependencies.\n",
    "\n",
    "    Example:\n",
    "        data = [\n",
    "            [{'id': 1, 'head': 2, 'deprel': 'nsubj'}, {'id': 2, 'head': 0, 'deprel': 'root'}],\n",
    "            [{'id': 1, 'head': 3, 'deprel': 'nsubj'}, {'id': 2, 'head': 3, 'deprel': 'aux'},\n",
    "             {'id': 3, 'head': 0, 'deprel': 'root'}]\n",
    "        ]\n",
    "        prop_initial, prop_final = get_pdd(data, deprel='nsubj')\n",
    "        print(f\"Proportion of head-initial dependencies: {prop_initial}\")\n",
    "        print(f\"Proportion of head-final dependencies: {prop_final}\")\n",
    "\n",
    "    Note:\n",
    "        - The function assumes that the input data follows the specified format.\n",
    "        - The 'id' key in each word dictionary represents the word's index in the sentence.\n",
    "        - The 'head' key represents the index of the head word to which the current word is dependent.\n",
    "        - The 'deprel' key represents the dependency relation between the current word and its head.\n",
    "        - The function returns (0, 0) if no suitable dependencies are found in the data.\n",
    "    \"\"\"\n",
    "    head_initial = 0\n",
    "    head_final = 0\n",
    "    \n",
    "    for sentence in parse_incr(data):    \n",
    "        for word in sentence:\n",
    "            if deprel is not None and word['deprel'] == deprel and word['deprel'] not in ['root','punct']:\n",
    "                if word['deprel'] == deprel:\n",
    "                    if word['head'] < word['id']:\n",
    "                        head_initial += 1\n",
    "                    else:\n",
    "                        head_final += 1\n",
    "            elif deprel is None and word['deprel'] not in ['root','punct']:\n",
    "                    if word['head'] < word['id']:\n",
    "                        head_initial += 1\n",
    "                    else:\n",
    "                        head_final += 1\n",
    "                        \n",
    "    total = head_initial + head_final\n",
    "    proportion_head_initial = head_initial / total\n",
    "    proportion_head_final = head_final / total\n",
    "\n",
    "    return proportion_head_initial, proportion_head_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mv(data,upos=None):\n",
    "    if upos != None:\n",
    "        num_depdents = 0\n",
    "        num_word = 0\n",
    "        for sentence in parse_incr(data):    \n",
    "            for word in sentence:\n",
    "                if word['deprel'] != 'punct' and word['upos'] == upos: \n",
    "                    depdents = [w for w in sentence if w['head'] == word['id']]\n",
    "                    num_depdents += len(depdents)\n",
    "                    num_word += 1\n",
    "        mean_valency = num_depdents/num_word\n",
    "        return mean_valency\n",
    "    elif upos == None:\n",
    "        num_depdents = 0\n",
    "        num_word = 0\n",
    "        for sentence in parse_incr(data):    \n",
    "            for word in sentence:\n",
    "                if word['deprel'] != 'punct': \n",
    "                    depdents = [w for w in sentence if w['head'] == word['id']]\n",
    "                    num_depdents += len(depdents)\n",
    "                    num_word += 1\n",
    "        mean_valency = num_depdents/num_word\n",
    "        return mean_valency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0631018923833255\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = open(r'D:\\数据集\\sud-treebanks-v2.11\\SUD_Chinese-GSD\\zh_gsd-sud-train.conllu',\"r\",encoding=\"utf-8\")\n",
    "print(get_mv(data,upos='VERB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
